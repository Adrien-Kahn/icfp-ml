{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmJE2a4N8We0"
   },
   "source": [
    "# Module 2: PyTorch tensors and automatic differentiation\n",
    "\n",
    "[Video timestamp](https://youtu.be/BmAS8IH7n3c?t=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOgNQwiv8We1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smvq6dbY8We4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vURcLof_8We8"
   },
   "source": [
    "Tensors are used to encode the signal to process, but also the internal states and parameters of models.\n",
    "\n",
    "**Manipulating data through this constrained structure allows to use CPUs and GPUs at peak performance.**\n",
    "\n",
    "Construct a 3x5 matrix, uninitialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9tmMiNo8We-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[9.2755e-39, 1.0561e-38, 8.9082e-39, 1.0469e-38, 9.2755e-39],\n",
      "        [4.2246e-39, 1.0286e-38, 1.0653e-38, 1.0194e-38, 8.4490e-39],\n",
      "        [1.0469e-38, 9.3674e-39, 9.9184e-39, 8.7245e-39, 9.2755e-39]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3,5)\n",
    "print(x.dtype)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlonXyHu8WfB"
   },
   "source": [
    "If you got an error this [stackoverflow link](https://stackoverflow.com/questions/50617917/overflow-when-unpacking-long-pytorch) might be useful..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlY-hwAY8WfB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2266,  0.6328,  1.4917,  0.6065,  0.8264],\n",
      "        [-0.1950,  0.1709, -0.4795, -0.6010, -1.4236],\n",
      "        [ 1.2294, -0.3296, -0.8624,  0.7584,  0.1417]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7g19ZvvL8WfD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPjoP9Ec8WfG"
   },
   "source": [
    "torch.Size is in fact a [tuple](https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences), so it supports the same operations.\n",
    "\n",
    "[Video timestamp](https://youtu.be/BmAS8IH7n3c?t=272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgVPlppm8WfG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CY87gW168WfI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size() == (3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jeUshrFT8WfK"
   },
   "source": [
    "### Bridge to numpy\n",
    "\n",
    "[Video timestamp](https://youtu.be/BmAS8IH7n3c?t=325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1cDkoT98WfM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2265537   0.6328068   1.4916524   0.60651654  0.8263821 ]\n",
      " [-0.19496761  0.17094342 -0.47948056 -0.60096526 -1.4236253 ]\n",
      " [ 1.2294048  -0.3296298  -0.86242515  0.75837725  0.14169262]]\n"
     ]
    }
   ],
   "source": [
    "y = x.numpy()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2DdMiBVY8WfO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a.dtype)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cg-kloHeB_hR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 tensor([1, 1, 1, 1, 1])\n",
      "torch.float64 tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "c = b.long()\n",
    "print(c.dtype, c)\n",
    "print(b.dtype, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZLbt9C38WfQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 tensor([[-1.9006,  0.2213,  1.8395, -0.9421,  0.8637],\n",
      "        [-0.9052,  0.6989,  0.3385, -1.8417, -0.7456],\n",
      "        [ 0.3636,  0.3216, -1.5531,  0.5260,  0.8010]])\n"
     ]
    }
   ],
   "source": [
    "xr = torch.randn(3, 5)\n",
    "print(xr.dtype, xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5nYMEcM8WfS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9006,  1.2213,  2.8395,  0.0579,  1.8637],\n",
       "        [ 0.0948,  1.6989,  1.3385, -0.8417,  0.2544],\n",
       "        [ 1.3636,  1.3216, -0.5531,  1.5260,  1.8010]], dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resb = xr + b\n",
    "resb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGTfk0M9B_hd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9006,  1.2213,  2.8395,  0.0579,  1.8637],\n",
       "        [ 0.0948,  1.6989,  1.3385, -0.8417,  0.2544],\n",
       "        [ 1.3636,  1.3216, -0.5531,  1.5260,  1.8010]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resc = xr + c\n",
    "resc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YuZ0-dswB_hf"
   },
   "source": [
    "Be careful with types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Jdin_2zB_hg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True],\n",
       "        [ True, False, False,  True,  True],\n",
       "        [False, False,  True, False, False]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resb == resc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rn7Xp9dpB_hk"
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipyVIQiKB_hn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6989342570, dtype=torch.float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resb[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dEdzZjHhB_hp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6989343166)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkYkbUJNB_hr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resc[0,1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCBKNjLdB_hu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2212979794)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wGdO-oaRB_hw"
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kt-CZCaZ8WgO"
   },
   "source": [
    "### [Broadcasting](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)\n",
    "\n",
    "[Video timestamp](https://youtu.be/BmAS8IH7n3c?t=670)\n",
    "\n",
    "Broadcasting automagically expands dimensions by replicating coefficients, when it is necessary to perform operations.\n",
    "\n",
    "1. If one of the tensors has fewer dimensions than the other, it is reshaped by adding as many dimensions of size 1 as necessary in the front; then\n",
    "2. for every mismatch, if one of the two tensor is of size one, it is expanded along this axis by replicating  coefficients.\n",
    "\n",
    "If there is a tensor size mismatch for one of the dimension and neither of them is one, the operation fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvB3V_ek8WgP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1.], [2.], [3.], [4.]])\n",
    "print(A.size())\n",
    "B = torch.tensor([[5., -5., 5., -5., 5.]])\n",
    "print(B.size())\n",
    "C = A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqqe1aTr8WgQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6., -4.,  6., -4.,  6.],\n",
       "        [ 7., -3.,  7., -3.,  7.],\n",
       "        [ 8., -2.,  8., -2.,  8.],\n",
       "        [ 9., -1.,  9., -1.,  9.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvj9kBUCB_h3"
   },
   "source": [
    "The original (column-)vector\n",
    "\\begin{eqnarray*}\n",
    "A = \\left( \\begin{array}{c}\n",
    "1\\\\\n",
    "2\\\\\n",
    "3\\\\\n",
    "4\\\\\n",
    "\\end{array}\\right)\n",
    "\\end{eqnarray*}\n",
    "is transformed into the matrix \n",
    "\\begin{eqnarray*}\n",
    "A = \\left( \\begin{array}{ccccc}\n",
    "1&1&1&1&1\\\\\n",
    "2&2&2&2&2\\\\\n",
    "3&3&3&3&3\\\\\n",
    "4&4&4&4&4\n",
    "\\end{array}\\right)\n",
    "\\end{eqnarray*}\n",
    "and the original (row-)vector\n",
    "\\begin{eqnarray*}\n",
    "C = (5,-5,5,-5,5)\n",
    "\\end{eqnarray*}\n",
    "is transformed into the matrix\n",
    "\\begin{eqnarray*}\n",
    "C = \\left( \\begin{array}{ccccc}\n",
    "5&-5&5&-5&5\\\\\n",
    "5&-5&5&-5&5\\\\\n",
    "5&-5&5&-5&5\\\\\n",
    "5&-5&5&-5&5\n",
    "\\end{array}\\right)\n",
    "\\end{eqnarray*}\n",
    "so that summing these matrices gives:\n",
    "\\begin{eqnarray*}\n",
    "A+C = \\left( \\begin{array}{ccccc}\n",
    "6&-4&6&-4&6\\\\\n",
    "7&-3&7&-3&7\\\\\n",
    "8&-2&8&-2&8\\\\\n",
    "9&-1&9&-1&9\n",
    "\\end{array}\\right)\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gq32MIeZB_h3"
   },
   "source": [
    "### In-place modification\n",
    "\n",
    "[Video timestamp](https://youtu.be/BmAS8IH7n3c?t=875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-V4Qvh2JB_h4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2266,  0.6328,  1.4917,  0.6065,  0.8264],\n",
       "        [-0.1950,  0.1709, -0.4795, -0.6010, -1.4236],\n",
       "        [ 1.2294, -0.3296, -0.8624,  0.7584,  0.1417]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VptqIf-0B_h7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9006,  0.2213,  1.8395, -0.9421,  0.8637],\n",
       "        [-0.9052,  0.6989,  0.3385, -1.8417, -0.7456],\n",
       "        [ 0.3636,  0.3216, -1.5531,  0.5260,  0.8010]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TlLf2SSZ8WfY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6740,  0.8541,  3.3311, -0.3356,  1.6900],\n",
      "        [-1.1002,  0.8699, -0.1409, -2.4426, -2.1693],\n",
      "        [ 1.5930, -0.0080, -2.4155,  1.2844,  0.9427]])\n"
     ]
    }
   ],
   "source": [
    "print(x+xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jk8j_AhL8Wfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6740,  0.8541,  3.3311, -0.3356,  1.6900],\n",
      "        [-1.1002,  0.8699, -0.1409, -2.4426, -2.1693],\n",
      "        [ 1.5930, -0.0080, -2.4155,  1.2844,  0.9427]])\n"
     ]
    }
   ],
   "source": [
    "x.add_(xr)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmB6aFc08Wfc"
   },
   "source": [
    "Any operation that mutates a tensor in-place is post-fixed with an ```_```\n",
    "\n",
    "For example: ```x.fill_(y)```, ```x.t_()```, will change ```x```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rzb4jk-d8Wfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6740, -1.1002,  1.5930],\n",
      "        [ 0.8541,  0.8699, -0.0080],\n",
      "        [ 3.3311, -0.1409, -2.4155],\n",
      "        [-0.3356, -2.4426,  1.2844],\n",
      "        [ 1.6900, -2.1693,  0.9427]])\n"
     ]
    }
   ],
   "source": [
    "print(x.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNXvqa_38Wff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6740, -1.1002,  1.5930],\n",
      "        [ 0.8541,  0.8699, -0.0080],\n",
      "        [ 3.3311, -0.1409, -2.4155],\n",
      "        [-0.3356, -2.4426,  1.2844],\n",
      "        [ 1.6900, -2.1693,  0.9427]])\n"
     ]
    }
   ],
   "source": [
    "x.t_()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zO4O1rJD8Wfi"
   },
   "source": [
    "### Shared memory\n",
    "\n",
    "[Video timestamp](https://youtu.be/BmAS8IH7n3c?t=990)\n",
    "\n",
    "Also be careful, changing the torch tensor modify the numpy array and vice-versa...\n",
    "\n",
    "This is explained in the PyTorch documentation [here](https://pytorch.org/docs/stable/torch.html#torch.from_numpy):\n",
    "The returned tensor by `torch.from_numpy` and ndarray share the same memory. Modifications to the tensor will be reflected in the ndarray and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYOR2MzI8Wfj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZP8DJXaC8Wfl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 0., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a[2] = 0\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ixqe4FEB_iL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 5. 1.]\n"
     ]
    }
   ],
   "source": [
    "b[3] = 5\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahC2FkEGB_iN"
   },
   "source": [
    "### Cuda\n",
    "\n",
    "[Video timestamp](https://youtu.be/BmAS8IH7n3c?t=1120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Aq_IjCa8Wfo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZ9T7v3L8Wfq"
   },
   "outputs": [],
   "source": [
    "#device = torch.device('cpu')\n",
    "device = torch.device('cuda') # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQv3WhHn8Wft"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKY8kHv_8Wfw"
   },
   "outputs": [],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z,z.type())\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1A7Q5VYK8Wfx"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:214\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    218\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnzdVsQW8HR3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DzbPRKV8Wfz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6497])\n",
      "0.6497234106063843\n",
      "[0.6497234]\n"
     ]
    }
   ],
   "source": [
    "# the following line is only useful if CUDA is available\n",
    "x = x.data\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ppop1eqWB_if"
   },
   "source": [
    "# Simple interfaces to standard image data-bases\n",
    "\n",
    "[Video timestamp](https://youtu.be/BmAS8IH7n3c?t=1354)\n",
    "\n",
    "An example, the [CIFAR10](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.CIFAR10) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7O6lDC88Wf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to content/data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f89e739dcd46c4b8da265049b9ff7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content/data\\cifar-10-python.tar.gz to content/data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "data_dir = 'content/data'\n",
    "\n",
    "cifar = torchvision.datasets.CIFAR10(data_dir, train = True, download = True)\n",
    "cifar.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JfIsAgwGB_ih"
   },
   "source": [
    "Documentation about the [`permute`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute) operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37KuS3m-B_ii"
   },
   "outputs": [],
   "source": [
    "x = torch.from_numpy(cifar.data).permute(0,3,1,2).float()\n",
    "x = x / 255\n",
    "print(x.type(), x.size(), x.min().item(), x.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dfrAC1GaB_ik"
   },
   "source": [
    "Documentation about the [`narrow(input, dim, start, length)`](https://pytorch.org/docs/stable/torch.html#torch.narrow) operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZUzzXJD8Wf3"
   },
   "outputs": [],
   "source": [
    "# Narrows to the first images, converts to float\n",
    "x = torch.narrow(x, 0, 0, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q5J3ohUMB_im"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVT7H5jS8Wf8"
   },
   "outputs": [],
   "source": [
    "# Showing images\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "show(torchvision.utils.make_grid(x, nrow = 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WuxYev_8Wf_"
   },
   "outputs": [],
   "source": [
    "# Kills the green and blue channels\n",
    "x.narrow(1, 1, 2).fill_(0)\n",
    "show(torchvision.utils.make_grid(x, nrow = 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QWopk2GX8WgB"
   },
   "source": [
    "# Autograd: automatic differentiation\n",
    "\n",
    "[Video timestamp](https://youtu.be/Z6H3zakmn6E?t=40)\n",
    "\n",
    "When executing tensor operations, PyTorch can automatically construct on-the-fly the graph of operations to compute the gradient of any quantity with respect to any tensor involved.\n",
    "\n",
    "To be more concrete, we introduce the following example: we consider parameters $w\\in \\mathbb{R}$ and $b\\in \\mathbb{R}$ with the corresponding function:\n",
    "\\begin{eqnarray*}\n",
    "\\ell = \\left(\\exp(wx+b) - y^* \\right)^2\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Our goal here, will be to compute the following partial derivatives:\n",
    "\\begin{eqnarray*}\n",
    "\\frac{\\partial \\ell}{\\partial w}\\mbox{ and, }\\frac{\\partial \\ell}{\\partial b}.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "The reason for doing this will be clear when you will solve the practicals for this lesson!\n",
    "\n",
    "You can decompose this function as a composition of basic operations. This is call the forward pass on the graph of operations.\n",
    "![backprop1](https://dataflowr.github.io/notebooks/Module2/img/backprop1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78AWWCb9B_iu"
   },
   "source": [
    "Let say we start with our model in `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4TEixrqxB_iv"
   },
   "outputs": [],
   "source": [
    "w = np.array([0.5])\n",
    "b = np.array([2])\n",
    "xx = np.array([0.5])#np.arange(0,1.5,.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZ8DlM8lB_iw"
   },
   "source": [
    "transform these into `tensor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKl5570iB_ix"
   },
   "outputs": [],
   "source": [
    "xx_t = torch.from_numpy(xx)\n",
    "w_t = torch.from_numpy(w)\n",
    "b_t = torch.from_numpy(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9PwWnxYB_iz"
   },
   "source": [
    "[Video timestamp](https://youtu.be/Z6H3zakmn6E?t=224)\n",
    "\n",
    "A `tensor` has a Boolean field `requires_grad`, set to `False` by default, which states if PyTorch should build the graph of operations so that gradients with respect to it can be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbWfbvtdB_iz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_t.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8rD3GLyB_i2"
   },
   "source": [
    "We want to take derivative with respect to $w$ so we change this value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iqS0CC8NB_i2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_t.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysa_qEvFB_i5"
   },
   "source": [
    "We want to do the same thing for $b$ but the following line will produce an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8pSa2V4yB_i5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_t.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EL0X9fIsB_i8"
   },
   "source": [
    "Reading the error message should allow you to correct the mistake!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "imH8JSXxB_i-"
   },
   "outputs": [],
   "source": [
    "dtype = torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLSSIn5jB_jA"
   },
   "outputs": [],
   "source": [
    "b_t = b_t.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6mpavg-B_jD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_t.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Melb8jo8B_jE"
   },
   "source": [
    "[Video timestamp](https://youtu.be/Z6H3zakmn6E?t=404)\n",
    "\n",
    "We now compute the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elI91IulB_jF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.4877], dtype=torch.float64, grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def fun(x,ystar):\n",
    "    y = torch.exp(w_t*x+b_t)\n",
    "    print(y)\n",
    "    return torch.sum((y-ystar)**2)\n",
    "\n",
    "ystar_t = torch.randn_like(xx_t)\n",
    "l_t = fun(xx_t,ystar_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q5qpcse1B_jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(83.5964, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WXzmCSdB_jI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_t.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJEjjKBFB_jK"
   },
   "source": [
    "After the computation is finished, i.e. *forward pass*, you can call ```.backward()``` and have all the gradients computed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1m1CowRB_jK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(w_t.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTw9bl4DB_jM"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [105]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ml_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "l_t.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4_zWnJkB_jO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([79.4625], dtype=torch.float64)\n",
      "tensor([158.9250], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(w_t.grad)\n",
    "print(b_t.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8fwcPgHB_jP"
   },
   "source": [
    "[Video timestamp](https://youtu.be/Z6H3zakmn6E?t=545)\n",
    "\n",
    "Let's try to understand these numbers...\n",
    "\n",
    "![backprop2](https://dataflowr.github.io/notebooks/Module2/img/backprop2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDV9lByQB_jP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(79.4625, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor(158.9250, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "yy_t = torch.exp(w_t*xx_t+b_t)\n",
    "print(torch.sum(2*(yy_t-ystar_t)*yy_t*xx_t))\n",
    "print(torch.sum(2*(yy_t-ystar_t)*yy_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMguUH4y8WgW"
   },
   "source": [
    "`tensor.backward()` accumulates the gradients in  the `grad` fields  of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70jDhm91B_jR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.4877], dtype=torch.float64, grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "l_t = fun(xx_t,ystar_t)\n",
    "l_t.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5H8BQOs8WgW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([158.9250], dtype=torch.float64)\n",
      "tensor([317.8500], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(w_t.grad)\n",
    "print(b_t.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1H2ZnVM5B_jU"
   },
   "source": [
    "By default, `backward` deletes the computational graph when it is used so that you will get an error below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06_uW2EwB_jU"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [109]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ml_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "l_t.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHxmIJj2B_jX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.4877], dtype=torch.float64, grad_fn=<ExpBackward0>)\n",
      "tensor([158.9250], dtype=torch.float64)\n",
      "tensor([317.8500], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Manually zero the gradients\n",
    "w_t.grad.data.zero_()\n",
    "b_t.grad.data.zero_()\n",
    "l_t = fun(xx_t,ystar_t)\n",
    "l_t.backward(retain_graph=True)\n",
    "l_t.backward()\n",
    "print(w_t.grad)\n",
    "print(b_t.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v40jAQEE8Wgu"
   },
   "source": [
    "The gradients must be set to zero manually. Otherwise they will cumulate across several _.backward()_ calls. \n",
    "This accumulating behavior is desirable in particular to compute the gradient of a loss summed over several “mini-batches,” or the gradient of a sum of losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAiS-TfqDOMU"
   },
   "source": [
    "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "02_basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
