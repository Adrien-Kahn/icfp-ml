{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8981832a",
   "metadata": {},
   "source": [
    "# ROC and Precision-Recall for Gaussian mixture models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de64630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc6b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "n_bins = 2\n",
    "mean = 2\n",
    "scale = 0.2\n",
    "\n",
    "def make_data(n_samples=n_samples, mean = mean, n_bins=n_bins, scale=scale):\n",
    "    centers = [(0, 0), (mean, 0)]\n",
    "    X, y = make_blobs(n_samples=n_samples, centers=centers, shuffle=False, random_state=42)\n",
    "    scaling = np.ones_like(X)\n",
    "    scaling[:,1] = ((scale-1)*y+1)\n",
    "    X = (scaling*X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d0a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "y_unique = np.unique(y_train)\n",
    "colors = cm.rainbow(np.linspace(0.0, 1.0, y_unique.size))\n",
    "for this_y, color in zip(y_unique, colors):\n",
    "    this_X = X_train[y_train == this_y]\n",
    "    plt.scatter(\n",
    "        this_X[:, 0],\n",
    "        this_X[:, 1],\n",
    "        c=color[np.newaxis, :],\n",
    "        alpha=0.5,\n",
    "        edgecolor=\"k\",\n",
    "        label=\"Class %s\" % this_y,\n",
    "    )\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3421a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc(model, X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    lr_probs = model.predict_proba(X_test)\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "    return lr_fpr, lr_tpr, lr_probs\n",
    "\n",
    "model_lg = LogisticRegression(solver='lbfgs')\n",
    "lr_fpr_lg, lr_tpr_lg, lr_probs_lg = compute_roc(model_lg)\n",
    "model_nb = GaussianNB()\n",
    "lr_fpr_nb, lr_tpr_nb, lr_probs_nb = compute_roc(model_nb)\n",
    "\n",
    "plt.plot(lr_fpr_lg, lr_tpr_lg, marker='.', label='Logistic')\n",
    "plt.plot(lr_fpr_nb, lr_tpr_nb, marker='.', label='Naive Bayes')\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10074bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_auc_lg = roc_auc_score(y_test, lr_probs_lg)\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc_lg))\n",
    "lr_auc_nb = roc_auc_score(y_test, lr_probs_nb)\n",
    "print('NB: ROC AUC=%.3f' % (lr_auc_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rocauc(model, X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test):\n",
    "    _, _, lr_probs = compute_roc(model, X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test)\n",
    "    return roc_auc_score(y_test, lr_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37080265",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_precision_lg, lr_recall_lg, _ = precision_recall_curve(y_test, lr_probs_lg)\n",
    "plt.plot(lr_recall_lg, lr_precision_lg, marker='.', label='Logistic')\n",
    "lr_precision_nb, lr_recall_nb, _ = precision_recall_curve(y_test, lr_probs_nb)\n",
    "plt.plot(lr_recall_nb, lr_precision_nb, marker='.', label='NB')\n",
    "no_skill = np.sum(y_test) / len(y_test)\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7cf998",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_lg = model_lg.predict(X_test)\n",
    "lr_f1_lg, lr_auc_lg = f1_score(y_test, y_predict_lg), auc(lr_recall_lg, lr_precision_lg)\n",
    "print('Logistic: F1=%.3f PR AUC=%.3f' % (lr_f1_lg, lr_auc_lg))\n",
    "\n",
    "y_predict_nb = model_nb.predict(X_test)\n",
    "lr_f1_nb, lr_auc_nb = f1_score(y_test, y_predict_nb), auc(lr_recall_nb, lr_precision_nb)\n",
    "print('NB: F1=%.3f PR AUC=%.3f' % (lr_f1_nb, lr_auc_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b049fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-icfp",
   "language": "python",
   "name": "ml-icfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
